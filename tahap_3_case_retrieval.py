# -*- coding: utf-8 -*-
"""TAHAP 3-Case Retrieval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VXYy0qd9gecX5MMPaM1PSg0lMO0g9fL5

# LIBRARY IMPORT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import warnings
warnings.filterwarnings('ignore')
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report, confusion_matrix
from transformers import AutoTokenizer, AutoModel
import torch
from torch.utils.data import Dataset, DataLoader
from wordcloud import WordCloud

"""# LOAD & EDA"""

print("=" * 50)
print("LOAD DATA & EDA")
print("=" * 50)

try:
    df = pd.read_csv('SCRAPING.csv')
    print("✓ Dataset berhasil dimuat dari file upload!")
except:
    print("File tidak ditemukan, menggunakan dummy data untuk demo...")

    df = pd.DataFrame({
        'no_id': range(1, 37),
        'nomor_perkara': [f'PK/{i}/2024' for i in range(1, 37)],
        'tanggal_penangkapan': ['2024-01-01'] * 36,
        'pasal': ['Pasal 362', 'Pasal 378', 'Pasal 340'] * 12,
        'hasil_mengadili': ['Dipidana', 'Bebas', 'Dipidana'] * 12
    })

print(f"Shape dataset: {df.shape}")
print("\nKolom dataset:")
print(df.columns.tolist())

print("\n" + "="*30 + " BASIC EDA " + "="*30)

print("\nInfo Dataset:")
print(df.info())

print("\nSample data (5 baris pertama):")
print(df.head())

print("\nCek missing values:")
missing_info = df.isnull().sum()
print(missing_info)

print("\nUnique values per kolom:")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")

print("\n" + "="*30 + " ANALISIS TARGET " + "="*30)
print("Distribusi hasil mengadili:")
target_counts = df['hasil_mengadili'].value_counts()
print(target_counts)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
target_counts.plot(kind='bar', color='skyblue')
plt.title('Distribusi Hasil Mengadili')
plt.xlabel('Hasil Mengadili')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)

plt.subplot(1, 2, 2)
colors = plt.cm.Set3(np.linspace(0, 1, len(target_counts)))
plt.pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%', colors=colors)
plt.title('Proporsi Hasil Mengadili')

plt.tight_layout()
plt.show()

print("\n" + "="*30 + " ANALISIS PASAL " + "="*30)
print("Distribusi pasal:")
pasal_counts = df['pasal'].value_counts()
print(pasal_counts)

if len(pasal_counts) > 1:
    pasal_text = ' '.join(df['pasal'].dropna().astype(str))
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(pasal_text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud - Pasal')
    plt.show()

"""# PRE-PROCESSING"""

print("\n" + "=" * 50)
print("PREPROCESSING")
print("=" * 50)

df_processed = df.copy()

def clean_text(text):
    if pd.isna(text):
        return ""
    text = str(text).lower()
    text = re.sub(r'[^a-zA-Z0-9\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    return text

df_processed['pasal_clean'] = df_processed['pasal'].apply(clean_text)

df_processed['text_features'] = df_processed['pasal_clean']

df_processed = df_processed.dropna(subset=['text_features', 'hasil_mengadili'])
df_processed = df_processed[df_processed['text_features'] != '']

print(f"Dataset setelah preprocessing: {df_processed.shape}")
print("Sample text setelah cleaning:")
print(df_processed[['pasal', 'pasal_clean', 'text_features']].head())

print(f"\nDistribusi hasil_mengadili setelah preprocessing:")
target_dist = df_processed['hasil_mengadili'].value_counts()
print(target_dist)

print(f"\n  Dataset sangat kecil ({len(df_processed)} sampel).")
print("Strategi untuk dataset kecil:")
print("1. Menggunakan cross-validation untuk evaluasi yang lebih robust")
print("2. Model sederhana untuk menghindari overfitting")
print("3. Parameter yang disesuaikan untuk dataset kecil")

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df_processed['target_encoded'] = le.fit_transform(df_processed['hasil_mengadili'])

print(f"\nTarget encoding:")
target_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print(target_mapping)

"""# DATA TRANSFORMATION"""

print("\n" + "=" * 50)
print("DATA TRANSFORMATION")
print("=" * 50)

print("3.1 TF-IDF Vectorization (optimized for small dataset)...")
tfidf_vectorizer = TfidfVectorizer(
    max_features=min(100, len(df_processed)),
    ngram_range=(1, 2),
    min_df=1,
    max_df=0.95,
    stop_words=None
)

X_tfidf = tfidf_vectorizer.fit_transform(df_processed['text_features'])
print(f"TF-IDF shape: {X_tfidf.shape}")
print(f"Feature names sample: {tfidf_vectorizer.get_feature_names_out()[:10]}")

print("\n3.2 BERT Embedding...")

model_name = "indobenchmark/indobert-base-p1"
tokenizer = AutoTokenizer.from_pretrained(model_name)
bert_model = AutoModel.from_pretrained(model_name)

def get_bert_embeddings(texts, batch_size=8):
    """Generate BERT embeddings for texts"""
    embeddings = []

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]

        encoded = tokenizer(
            batch_texts,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors='pt'
        )

        with torch.no_grad():
            outputs = bert_model(**encoded)
            batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()
            embeddings.extend(batch_embeddings)

    return np.array(embeddings)

print(f"Generating BERT embeddings for all {len(df_processed)} samples...")
X_bert = get_bert_embeddings(df_processed['text_features'].tolist())
print(f"BERT embeddings shape: {X_bert.shape}")

print("\n3.3 Cross-Validation Setup...")

n_splits = min(5, len(target_dist))
print(f"Using {n_splits}-fold cross-validation")

cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

test_size = max(0.2, 1.0/len(df_processed))
try:
    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(
        X_tfidf, df_processed['target_encoded'],
        test_size=test_size, random_state=42, stratify=df_processed['target_encoded']
    )
    X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(
        X_bert, df_processed['target_encoded'],
        test_size=test_size, random_state=42, stratify=df_processed['target_encoded']
    )
    print("✓ Stratified split berhasil")
except:

    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(
        X_tfidf, df_processed['target_encoded'],
        test_size=test_size, random_state=42
    )
    X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(
        X_bert, df_processed['target_encoded'],
        test_size=test_size, random_state=42
    )
    print("  Menggunakan random split")

print(f"Train/Test split:")
print(f"TF-IDF - Train: {X_train_tfidf.shape}, Test: {X_test_tfidf.shape}")
print(f"BERT - Train: {X_train_bert.shape}, Test: {X_test_bert.shape}")

print("\n" + "=" * 50)
print("MODEL TRAINING & CROSS-VALIDATION")
print("=" * 50)

cv_results = {}
final_results = {}

models = {
    'Logistic Regression + TF-IDF': (LogisticRegression(random_state=42, max_iter=1000), 'tfidf'),
    'SVM (Linear) + TF-IDF': (SVC(kernel='linear', random_state=42, probability=True), 'tfidf'),
    'Naive Bayes + TF-IDF': (MultinomialNB(), 'tfidf'),
    'Logistic Regression + BERT': (LogisticRegression(random_state=42, max_iter=1000), 'bert'),
    'SVM (Linear) + BERT': (SVC(kernel='linear', random_state=42, probability=True), 'bert')
}

print("Running Cross-Validation...")
for model_name, (model, feature_type) in models.items():
    print(f"\nEvaluating {model_name}...")

    if feature_type == 'tfidf':
        X = X_tfidf
    else:
        X = X_bert

    y = df_processed['target_encoded']

    try:
        cv_scores = cross_val_score(model, X, y, cv=cv, scoring='f1_weighted')
        cv_results[model_name] = {
            'mean_f1': cv_scores.mean(),
            'std_f1': cv_scores.std(),
            'scores': cv_scores
        }
        print(f"CV F1-Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
    except Exception as e:
        print(f"CV failed for {model_name}: {e}")
        cv_results[model_name] = {
            'mean_f1': 0,
            'std_f1': 0,
            'scores': [0]
        }

print("\n" + "="*30 + " FINAL MODEL TESTING " + "="*30)

for model_name, (model, feature_type) in models.items():
    print(f"\nTraining final {model_name}...")

    if feature_type == 'tfidf':
        X_train, X_test = X_train_tfidf, X_test_tfidf
        y_train, y_test = y_train_tfidf, y_test_tfidf
    else:
        X_train, X_test = X_train_bert, X_test_bert
        y_train, y_test = y_train_bert, y_test_bert

    try:

        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)


        final_results[model_name] = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),
            'recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),
            'f1': f1_score(y_test, y_pred, average='weighted', zero_division=0)
        }

        print(f"Test Accuracy: {final_results[model_name]['accuracy']:.3f}")
        print(f"Test F1-Score: {final_results[model_name]['f1']:.3f}")

    except Exception as e:
        print(f"Training failed for {model_name}: {e}")
        final_results[model_name] = {
            'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0
        }

def retrieve_similar_cases(query_text, model, vectorizer=None, top_k=5):
    """
    Fungsi untuk retrieve kasus serupa berdasarkan query
    """
    try:
        if vectorizer:
            query_vector = vectorizer.transform([clean_text(query_text)])
            prediction = model.predict(query_vector)[0]
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(query_vector)[0]
                confidence = np.max(proba)
            else:
                confidence = 0.5
            return prediction, confidence
        else:  # BERT based
            query_embedding = get_bert_embeddings([clean_text(query_text)])
            prediction = model.predict(query_embedding)[0]
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(query_embedding)[0]
                confidence = np.max(proba)
            else:
                confidence = 0.5
            return prediction, confidence
    except Exception as e:
        print(f"Retrieval error: {e}")
        return 0, 0.0

"""# EVALUASI"""

print("\n" + "=" * 50)
print("MODEL EVALUATION & VISUALIZATION")
print("=" * 50)

print("4.1 Cross-Validation Results:")
cv_df = pd.DataFrame({
    model: {'Mean F1': results['mean_f1'], 'Std F1': results['std_f1']}
    for model, results in cv_results.items()
}).T
print(cv_df.round(4))

print("\n4.2 Final Test Results:")
final_df = pd.DataFrame(final_results).T
print(final_df.round(4))

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

ax = axes[0, 0]
models_list = list(cv_results.keys())
cv_means = [cv_results[model]['mean_f1'] for model in models_list]
cv_stds = [cv_results[model]['std_f1'] for model in models_list]

bars = ax.bar(range(len(models_list)), cv_means, yerr=cv_stds, capsize=5)
ax.set_title('Cross-Validation F1-Scores')
ax.set_ylabel('F1-Score')
ax.set_xticks(range(len(models_list)))
ax.set_xticklabels(models_list, rotation=45, ha='right')
ax.set_ylim(0, 1.1)

metrics = ['accuracy', 'precision', 'recall', 'f1']
for i, metric in enumerate(metrics):
    if i == 0:
        continue
    ax = axes[(i)//2, (i)%2]
    metric_values = [final_results[model][metric] for model in final_results.keys()]
    bars = ax.bar(final_results.keys(), metric_values)
    ax.set_title(f'{metric.title()} - Final Test')
    ax.set_ylabel(metric.title())
    ax.tick_params(axis='x', rotation=45)
    ax.set_ylim(0, 1.1)

    for bar, value in zip(bars, metric_values):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{value:.3f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

if final_results:
    best_model = max(final_results.keys(), key=lambda x: final_results[x]['f1'])
    print(f"\n4.4 Best Model: {best_model}")
    print(f"Best F1-Score: {final_results[best_model]['f1']:.4f}")

    print(f"\nTesting Retrieval Function dengan {best_model}...")
    test_query = "pasal 362 pencurian"
    print(f"Query: '{test_query}'")

    model_obj, feature_type = models[best_model]
    if feature_type == 'tfidf':
        model_obj.fit(X_train_tfidf, y_train_tfidf)
        pred, conf = retrieve_similar_cases(test_query, model_obj, tfidf_vectorizer)
    else:
        model_obj.fit(X_train_bert, y_train_bert)
        pred, conf = retrieve_similar_cases(test_query, model_obj)

    try:
        result = le.inverse_transform([pred])[0]
        print(f"Prediction: {result} (confidence: {conf:.3f})")
    except:
        print("Unable to show prediction")

print("\n" + "="*30 + " DATASET INSIGHTS " + "="*30)
print(f"Dataset size: {len(df_processed)} samples")
print(f"Number of classes: {len(le.classes_)}")
print(f"Classes: {le.classes_}")
print(f"Class distribution: {dict(zip(le.classes_, np.bincount(df_processed['target_encoded'])))}")

"""# DEMO UJICOBA"""

# Langkah 1: Mount Google Drive di Colab
from google.colab import drive
drive.mount('/content/drive')

# Langkah 2: Tentukan path file HTML yang ada di Google Drive
# Gantilah path dengan lokasi file HTML di Google Drive Anda
file_path = '/content/drive/My Drive/TA_PENALARAN_KOMPUTER/modelhtml.html'

# Langkah 3: Tampilkan HTML menggunakan IPython display
from IPython.display import display, HTML

# Menampilkan file HTML di Colab
display(HTML(file_path))